# -*- coding: utf-8 -*-
"""IA-UI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JuHaWKsdd4TAwQuYc_qMZjlIcQkLFguV
"""

!pip install kaggle

# PredicciÃ³n de Retrasos de AerolÃ­neas usando RegresiÃ³n Lineal
# Dataset: Airlines Dataset to predict a delay

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de grÃ¡ficos
plt.style.use('default')
sns.set_palette("husl")

print("ğŸ›©ï¸ AnÃ¡lisis y PredicciÃ³n de Retrasos de AerolÃ­neas")
print("=" * 50)

# 1. CARGAR EL DATASET
print("\nğŸ“Š Cargando dataset...")

# Reemplaza 'ruta_del_archivo.csv' con la ruta real de tu archivo CSV
# En Colab, puedes subir el archivo y usar: df = pd.read_csv('/content/nombre_archivo.csv')
try:
    # Ejemplo de rutas comunes en Colab:
    df = pd.read_csv('./Airlines.csv')  # Si subes el archivo directamente
    # df = pd.read_csv('Airlines.csv')  # Si estÃ¡ en la carpeta actual
    print("âœ… Dataset cargado exitosamente!")
except FileNotFoundError:
    print("âŒ Error: No se encontrÃ³ el archivo CSV.")
    print("ğŸ’¡ Sugerencia: Sube el archivo a Colab o verifica la ruta.")
    print("   Puedes usar: files.upload() para subir archivos")
    # CÃ³digo para subir archivos en Colab
    from google.colab import files
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
    df = pd.read_csv(filename)

# 2. EXPLORACIÃ“N INICIAL DE DATOS
print(f"\nğŸ“‹ InformaciÃ³n del dataset:")
print(f"   â€¢ Dimensiones: {df.shape}")
print(f"   â€¢ Columnas: {list(df.columns)}")

print(f"\nğŸ” Primeras 5 filas:")
print(df.head())

print(f"\nğŸ“ˆ InformaciÃ³n estadÃ­stica:")
print(df.describe())

print(f"\nğŸ” Valores nulos por columna:")
print(df.isnull().sum())

print(f"\nğŸ“Š Tipos de datos:")
print(df.dtypes)

# 3. ANÃLISIS EXPLORATORIO
print("\nğŸ“Š Realizando anÃ¡lisis exploratorio...")

# Crear figura con subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# GrÃ¡fico 1: DistribuciÃ³n de retrasos (si existe columna de delay)
delay_columns = [col for col in df.columns if 'delay' in col.lower() or 'late' in col.lower()]
if delay_columns:
    target_col = delay_columns[0]
    axes[0, 0].hist(df[target_col].dropna(), bins=50, alpha=0.7, color='skyblue')
    axes[0, 0].set_title(f'DistribuciÃ³n de {target_col}')
    axes[0, 0].set_xlabel(target_col)
    axes[0, 0].set_ylabel('Frecuencia')

# GrÃ¡fico 2: Matriz de correlaciÃ³n
numeric_cols = df.select_dtypes(include=[np.number]).columns
if len(numeric_cols) > 1:
    corr_matrix = df[numeric_cols].corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0, 1])
    axes[0, 1].set_title('Matriz de CorrelaciÃ³n')

# GrÃ¡fico 3: Boxplot de variables categÃ³ricas importantes
categorical_cols = df.select_dtypes(include=['object']).columns
if len(categorical_cols) > 0:
    sample_cat = categorical_cols[0]
    if len(df[sample_cat].unique()) < 20:  # Solo si no hay demasiadas categorÃ­as
        df.boxplot(column=numeric_cols[0], by=sample_cat, ax=axes[1, 0])
        axes[1, 0].set_title(f'{numeric_cols[0]} por {sample_cat}')

# GrÃ¡fico 4: Scatter plot de dos variables numÃ©ricas
if len(numeric_cols) >= 2:
    axes[1, 1].scatter(df[numeric_cols[0]], df[numeric_cols[1]], alpha=0.6)
    axes[1, 1].set_xlabel(numeric_cols[0])
    axes[1, 1].set_ylabel(numeric_cols[1])
    axes[1, 1].set_title(f'{numeric_cols[0]} vs {numeric_cols[1]}')

plt.tight_layout()
plt.show()

# 4. PREPROCESAMIENTO DE DATOS
print("\nğŸ”§ Preprocesando datos...")

# Crear una copia para el preprocesamiento
df_processed = df.copy()

# Manejar valores nulos
print("ğŸ§¹ Limpiando valores nulos...")
for col in df_processed.columns:
    if df_processed[col].dtype == 'object':
        # Para categÃ³ricas, rellenar con la moda
        df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)
    else:
        # Para numÃ©ricas, rellenar con la mediana
        df_processed[col].fillna(df_processed[col].median(), inplace=True)

# Codificar variables categÃ³ricas
print("ğŸ”¢ Codificando variables categÃ³ricas...")
label_encoders = {}
for col in df_processed.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df_processed[col] = le.fit_transform(df_processed[col].astype(str))
    label_encoders[col] = le
    print(f"   â€¢ {col}: {len(le.classes_)} categorÃ­as Ãºnicas")

# 5. DEFINIR VARIABLES PREDICTORAS Y TARGET
print("\nğŸ¯ Definiendo variables...")

# Excluir columna 'id' si existe
exclude_cols = ['id']

# Intentar identificar automÃ¡ticamente la variable objetivo
possible_targets = [col for col in df_processed.columns
                   if any(keyword in col.lower() for keyword in
                         ['delay', 'late', 'target', 'label', 'y'])]

if possible_targets:
    target_column = possible_targets[0]
    print(f"   â€¢ Variable objetivo detectada: {target_column}")
else:
    # Si no se encuentra automÃ¡ticamente, usar la Ãºltima columna
    target_column = df_processed.columns[-1]
    print(f"   â€¢ Usando Ãºltima columna como objetivo: {target_column}")

# Definir X (caracterÃ­sticas) e y (objetivo), excluyendo columnas innecesarias
X = df_processed.drop(columns=[target_column] + [col for col in exclude_cols if col in df_processed.columns])
y = df_processed[target_column]

print(f"   â€¢ CaracterÃ­sticas (X): {X.shape[1]} variables")
print(f"   â€¢ Variable objetivo (y): {target_column}")
print(f"   â€¢ CaracterÃ­sticas incluidas: {list(X.columns)}")

# 6. DIVIDIR DATOS EN ENTRENAMIENTO Y PRUEBA
print("\nğŸ“Š Dividiendo datos...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"   â€¢ Datos de entrenamiento: {X_train.shape[0]} muestras")
print(f"   â€¢ Datos de prueba: {X_test.shape[0]} muestras")

# 7. ESCALAR LAS CARACTERÃSTICAS
print("\nâš–ï¸ Escalando caracterÃ­sticas...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 8. ENTRENAR EL MODELO DE REGRESIÃ“N LINEAL
print("\nğŸ¤– Entrenando modelo de RegresiÃ³n Lineal...")
model = LinearRegression()
model.fit(X_train_scaled, y_train)
print("âœ… Modelo entrenado exitosamente!")

# 9. HACER PREDICCIONES
print("\nğŸ”® Realizando predicciones...")
y_train_pred = model.predict(X_train_scaled)
y_test_pred = model.predict(X_test_scaled)

# 10. EVALUAR EL MODELO
print("\nğŸ“Š EvaluaciÃ³n del modelo:")
print("=" * 30)

# MÃ©tricas de entrenamiento
train_mse = mean_squared_error(y_train, y_train_pred)
train_rmse = np.sqrt(train_mse)
train_mae = mean_absolute_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

# MÃ©tricas de prueba
test_mse = mean_squared_error(y_test, y_test_pred)
test_rmse = np.sqrt(test_mse)
test_mae = mean_absolute_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"ğŸ“ˆ DATOS DE ENTRENAMIENTO:")
print(f"   â€¢ RÂ² Score: {train_r2:.4f}")
print(f"   â€¢ RMSE: {train_rmse:.4f}")
print(f"   â€¢ MAE: {train_mae:.4f}")
print(f"   â€¢ MSE: {train_mse:.4f}")

print(f"\nğŸ“Š DATOS DE PRUEBA:")
print(f"   â€¢ RÂ² Score: {test_r2:.4f}")
print(f"   â€¢ RMSE: {test_rmse:.4f}")
print(f"   â€¢ MAE: {test_mae:.4f}")
print(f"   â€¢ MSE: {test_mse:.4f}")

# 11. VISUALIZAR RESULTADOS
print("\nğŸ“Š Generando visualizaciones...")

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# GrÃ¡fico 1: Valores reales vs predicciones (entrenamiento)
axes[0, 0].scatter(y_train, y_train_pred, alpha=0.6, color='blue')
axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)
axes[0, 0].set_xlabel('Valores Reales')
axes[0, 0].set_ylabel('Predicciones')
axes[0, 0].set_title(f'Entrenamiento: Real vs PredicciÃ³n (RÂ² = {train_r2:.3f})')

# GrÃ¡fico 2: Valores reales vs predicciones (prueba)
axes[0, 1].scatter(y_test, y_test_pred, alpha=0.6, color='green')
axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
axes[0, 1].set_xlabel('Valores Reales')
axes[0, 1].set_ylabel('Predicciones')
axes[0, 1].set_title(f'Prueba: Real vs PredicciÃ³n (RÂ² = {test_r2:.3f})')

# GrÃ¡fico 3: Residuos (entrenamiento)
train_residuals = y_train - y_train_pred
axes[1, 0].scatter(y_train_pred, train_residuals, alpha=0.6, color='blue')
axes[1, 0].axhline(y=0, color='r', linestyle='--')
axes[1, 0].set_xlabel('Predicciones')
axes[1, 0].set_ylabel('Residuos')
axes[1, 0].set_title('Residuos - Entrenamiento')

# GrÃ¡fico 4: Residuos (prueba)
test_residuals = y_test - y_test_pred
axes[1, 1].scatter(y_test_pred, test_residuals, alpha=0.6, color='green')
axes[1, 1].axhline(y=0, color='r', linestyle='--')
axes[1, 1].set_xlabel('Predicciones')
axes[1, 1].set_ylabel('Residuos')
axes[1, 1].set_title('Residuos - Prueba')

plt.tight_layout()
plt.show()

# 12. IMPORTANCIA DE LAS CARACTERÃSTICAS
print("\nğŸ¯ Importancia de las caracterÃ­sticas:")
print("=" * 40)

feature_importance = pd.DataFrame({
    'CaracterÃ­stica': X.columns,
    'Coeficiente': model.coef_,
    'Importancia_Abs': np.abs(model.coef_)
}).sort_values('Importancia_Abs', ascending=False)

print(feature_importance)

# Visualizar importancia de caracterÃ­sticas
plt.figure(figsize=(10, 8))
top_features = feature_importance.head(10)
plt.barh(top_features['CaracterÃ­stica'], top_features['Coeficiente'])
plt.xlabel('Coeficiente')
plt.title('Top 10 CaracterÃ­sticas mÃ¡s Importantes')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# 13. EJEMPLOS DE PREDICCIÃ“N
print("\nğŸ”® Ejemplos de predicciones:")
print("=" * 30)

# Mostrar algunas predicciones de ejemplo
example_indices = np.random.choice(len(y_test), 5, replace=False)
for i, idx in enumerate(example_indices):
    real_value = y_test.iloc[idx]
    predicted_value = y_test_pred[idx]
    print(f"Ejemplo {i+1}:")
    print(f"   â€¢ Valor real: {real_value:.2f}")
    print(f"   â€¢ PredicciÃ³n: {predicted_value:.2f}")
    print(f"   â€¢ Error: {abs(real_value - predicted_value):.2f}")
    print()

# 14. RESUMEN FINAL
print("\nğŸ“‹ RESUMEN FINAL:")
print("=" * 20)
print(f"âœ… Modelo entrenado exitosamente")
print(f"ğŸ“Š RÂ² Score en prueba: {test_r2:.4f}")
print(f"ğŸ“‰ RMSE en prueba: {test_rmse:.4f}")
print(f"ğŸ¯ El modelo explica el {test_r2*100:.1f}% de la varianza en los datos de prueba")

if test_r2 > 0.7:
    print("ğŸ‰ Â¡Excelente rendimiento del modelo!")
elif test_r2 > 0.5:
    print("ğŸ‘ Buen rendimiento del modelo")
elif test_r2 > 0.3:
    print("âš ï¸ Rendimiento moderado - considera mÃ¡s caracterÃ­sticas o diferente modelo")
else:
    print("âŒ Rendimiento bajo - revisa los datos y considera otros enfoques")

print(f"\nğŸ’¡ CaracterÃ­stica mÃ¡s importante: {feature_importance.iloc[0]['CaracterÃ­stica']}")
print(f"ğŸ”§ Total de caracterÃ­sticas usadas: {len(X.columns)}")

print("\nğŸš€ Â¡AnÃ¡lisis completado!")