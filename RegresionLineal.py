# -*- coding: utf-8 -*-
"""IA-UI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JuHaWKsdd4TAwQuYc_qMZjlIcQkLFguV
"""

!pip install kaggle

# Predicci√≥n de Retrasos de Aerol√≠neas usando Regresi√≥n Lineal
# Dataset: Airlines Dataset to predict a delay

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de gr√°ficos
plt.style.use('default')
sns.set_palette("husl")

print("üõ©Ô∏è An√°lisis y Predicci√≥n de Retrasos de Aerol√≠neas")
print("=" * 50)

# 1. CARGAR EL DATASET
print("\nüìä Cargando dataset...")

# Reemplaza 'ruta_del_archivo.csv' con la ruta real de tu archivo CSV
# En Colab, puedes subir el archivo y usar: df = pd.read_csv('/content/nombre_archivo.csv')
try:
    # Ejemplo de rutas comunes en Colab:
    df = pd.read_csv('./Airlines.csv')  # Si subes el archivo directamente
    # df = pd.read_csv('Airlines.csv')  # Si est√° en la carpeta actual
    print("‚úÖ Dataset cargado exitosamente!")
except FileNotFoundError:
    print("‚ùå Error: No se encontr√≥ el archivo CSV.")
    print("üí° Sugerencia: Sube el archivo a Colab o verifica la ruta.")
    print("   Puedes usar: files.upload() para subir archivos")
    # C√≥digo para subir archivos en Colab
    from google.colab import files
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
    df = pd.read_csv(filename)

# 2. EXPLORACI√ìN INICIAL DE DATOS
print(f"\nüìã Informaci√≥n del dataset:")
print(f"   ‚Ä¢ Dimensiones: {df.shape}")
print(f"   ‚Ä¢ Columnas: {list(df.columns)}")

print(f"\nüîç Primeras 5 filas:")
print(df.head())

print(f"\nüìà Informaci√≥n estad√≠stica:")
print(df.describe())

print(f"\nüîç Valores nulos por columna:")
print(df.isnull().sum())

print(f"\nüìä Tipos de datos:")
print(df.dtypes)

# 3. AN√ÅLISIS EXPLORATORIO
print("\nüìä Realizando an√°lisis exploratorio...")

# Crear figura con subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Gr√°fico 1: Distribuci√≥n de retrasos (si existe columna de delay)
delay_columns = [col for col in df.columns if 'delay' in col.lower() or 'late' in col.lower()]
if delay_columns:
    target_col = delay_columns[0]
    axes[0, 0].hist(df[target_col].dropna(), bins=50, alpha=0.7, color='skyblue')
    axes[0, 0].set_title(f'Distribuci√≥n de {target_col}')
    axes[0, 0].set_xlabel(target_col)
    axes[0, 0].set_ylabel('Frecuencia')

# Gr√°fico 2: Matriz de correlaci√≥n
numeric_cols = df.select_dtypes(include=[np.number]).columns
if len(numeric_cols) > 1:
    corr_matrix = df[numeric_cols].corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0, 1])
    axes[0, 1].set_title('Matriz de Correlaci√≥n')

# Gr√°fico 3: Boxplot de variables categ√≥ricas importantes
categorical_cols = df.select_dtypes(include=['object']).columns
if len(categorical_cols) > 0:
    sample_cat = categorical_cols[0]
    if len(df[sample_cat].unique()) < 20:  # Solo si no hay demasiadas categor√≠as
        df.boxplot(column=numeric_cols[0], by=sample_cat, ax=axes[1, 0])
        axes[1, 0].set_title(f'{numeric_cols[0]} por {sample_cat}')

# Gr√°fico 4: Scatter plot de dos variables num√©ricas
if len(numeric_cols) >= 2:
    axes[1, 1].scatter(df[numeric_cols[0]], df[numeric_cols[1]], alpha=0.6)
    axes[1, 1].set_xlabel(numeric_cols[0])
    axes[1, 1].set_ylabel(numeric_cols[1])
    axes[1, 1].set_title(f'{numeric_cols[0]} vs {numeric_cols[1]}')

plt.tight_layout()
plt.show()

# 4. PREPROCESAMIENTO DE DATOS
print("\nüîß Preprocesando datos...")

# Crear una copia para el preprocesamiento
df_processed = df.copy()

# Manejar valores nulos
print("üßπ Limpiando valores nulos...")
for col in df_processed.columns:
    if df_processed[col].dtype == 'object':
        # Para categ√≥ricas, rellenar con la moda
        df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)
    else:
        # Para num√©ricas, rellenar con la mediana
        df_processed[col].fillna(df_processed[col].median(), inplace=True)

# Codificar variables categ√≥ricas
print("üî¢ Codificando variables categ√≥ricas...")
label_encoders = {}
for col in df_processed.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df_processed[col] = le.fit_transform(df_processed[col].astype(str))
    label_encoders[col] = le
    print(f"   ‚Ä¢ {col}: {len(le.classes_)} categor√≠as √∫nicas")

# 5. DEFINIR VARIABLES PREDICTORAS Y TARGET
print("\nüéØ Definiendo variables...")

# Excluir columna 'id' si existe
exclude_cols = ['id']

# Intentar identificar autom√°ticamente la variable objetivo
possible_targets = [col for col in df_processed.columns
                   if any(keyword in col.lower() for keyword in
                         ['delay', 'late', 'target', 'label', 'y'])]

if possible_targets:
    target_column = possible_targets[0]
    print(f"   ‚Ä¢ Variable objetivo detectada: {target_column}")
else:
    # Si no se encuentra autom√°ticamente, usar la √∫ltima columna
    target_column = df_processed.columns[-1]
    print(f"   ‚Ä¢ Usando √∫ltima columna como objetivo: {target_column}")

# Definir X (caracter√≠sticas) e y (objetivo), excluyendo columnas innecesarias
X = df_processed.drop(columns=[target_column] + [col for col in exclude_cols if col in df_processed.columns])
y = df_processed[target_column]

print(f"   ‚Ä¢ Caracter√≠sticas (X): {X.shape[1]} variables")
print(f"   ‚Ä¢ Variable objetivo (y): {target_column}")
print(f"   ‚Ä¢ Caracter√≠sticas incluidas: {list(X.columns)}")

# 6. DIVIDIR DATOS EN ENTRENAMIENTO Y PRUEBA
print("\nüìä Dividiendo datos...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"   ‚Ä¢ Datos de entrenamiento: {X_train.shape[0]} muestras")
print(f"   ‚Ä¢ Datos de prueba: {X_test.shape[0]} muestras")

# 7. ESCALAR LAS CARACTER√çSTICAS
print("\n‚öñÔ∏è Escalando caracter√≠sticas...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 8. ENTRENAR EL MODELO DE REGRESI√ìN LINEAL
print("\nü§ñ Entrenando modelo de Regresi√≥n Lineal...")
model = LinearRegression()
model.fit(X_train_scaled, y_train)
print("‚úÖ Modelo entrenado exitosamente!")

# 9. HACER PREDICCIONES
print("\nüîÆ Realizando predicciones...")
y_train_pred = model.predict(X_train_scaled)
y_test_pred = model.predict(X_test_scaled)

# 10. EVALUAR EL MODELO
print("\nüìä Evaluaci√≥n del modelo:")
print("=" * 30)

# M√©tricas de entrenamiento
train_mse = mean_squared_error(y_train, y_train_pred)
train_rmse = np.sqrt(train_mse)
train_mae = mean_absolute_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

# M√©tricas de prueba
test_mse = mean_squared_error(y_test, y_test_pred)
test_rmse = np.sqrt(test_mse)
test_mae = mean_absolute_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"üìà DATOS DE ENTRENAMIENTO:")
print(f"   ‚Ä¢ R¬≤ Score: {train_r2:.4f}")
print(f"   ‚Ä¢ RMSE: {train_rmse:.4f}")
print(f"   ‚Ä¢ MAE: {train_mae:.4f}")
print(f"   ‚Ä¢ MSE: {train_mse:.4f}")

print(f"\nüìä DATOS DE PRUEBA:")
print(f"   ‚Ä¢ R¬≤ Score: {test_r2:.4f}")
print(f"   ‚Ä¢ RMSE: {test_rmse:.4f}")
print(f"   ‚Ä¢ MAE: {test_mae:.4f}")
print(f"   ‚Ä¢ MSE: {test_mse:.4f}")

# 11. VISUALIZAR RESULTADOS
print("\nüìä Generando visualizaciones...")

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Gr√°fico 1: Valores reales vs predicciones (entrenamiento)
axes[0, 0].scatter(y_train, y_train_pred, alpha=0.6, color='blue')
axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)
axes[0, 0].set_xlabel('Valores Reales')
axes[0, 0].set_ylabel('Predicciones')
axes[0, 0].set_title(f'Entrenamiento: Real vs Predicci√≥n (R¬≤ = {train_r2:.3f})')

# Gr√°fico 2: Valores reales vs predicciones (prueba)
axes[0, 1].scatter(y_test, y_test_pred, alpha=0.6, color='green')
axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
axes[0, 1].set_xlabel('Valores Reales')
axes[0, 1].set_ylabel('Predicciones')
axes[0, 1].set_title(f'Prueba: Real vs Predicci√≥n (R¬≤ = {test_r2:.3f})')

# Gr√°fico 3: Residuos (entrenamiento)
train_residuals = y_train - y_train_pred
axes[1, 0].scatter(y_train_pred, train_residuals, alpha=0.6, color='blue')
axes[1, 0].axhline(y=0, color='r', linestyle='--')
axes[1, 0].set_xlabel('Predicciones')
axes[1, 0].set_ylabel('Residuos')
axes[1, 0].set_title('Residuos - Entrenamiento')

# Gr√°fico 4: Residuos (prueba)
test_residuals = y_test - y_test_pred
axes[1, 1].scatter(y_test_pred, test_residuals, alpha=0.6, color='green')
axes[1, 1].axhline(y=0, color='r', linestyle='--')
axes[1, 1].set_xlabel('Predicciones')
axes[1, 1].set_ylabel('Residuos')
axes[1, 1].set_title('Residuos - Prueba')

plt.tight_layout()
plt.show()

# 12. IMPORTANCIA DE LAS CARACTER√çSTICAS
print("\nüéØ Importancia de las caracter√≠sticas:")
print("=" * 40)

feature_importance = pd.DataFrame({
    'Caracter√≠stica': X.columns,
    'Coeficiente': model.coef_,
    'Importancia_Abs': np.abs(model.coef_)
}).sort_values('Importancia_Abs', ascending=False)

print(feature_importance)

# Visualizar importancia de caracter√≠sticas
plt.figure(figsize=(10, 8))
top_features = feature_importance.head(10)
plt.barh(top_features['Caracter√≠stica'], top_features['Coeficiente'])
plt.xlabel('Coeficiente')
plt.title('Top 10 Caracter√≠sticas m√°s Importantes')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# 13. EJEMPLOS DE PREDICCI√ìN
print("\nüîÆ Ejemplos de predicciones:")
print("=" * 30)

# Mostrar algunas predicciones de ejemplo
example_indices = np.random.choice(len(y_test), 5, replace=False)
for i, idx in enumerate(example_indices):
    real_value = y_test.iloc[idx]
    predicted_value = y_test_pred[idx]
    print(f"Ejemplo {i+1}:")
    print(f"   ‚Ä¢ Valor real: {real_value:.2f}")
    print(f"   ‚Ä¢ Predicci√≥n: {predicted_value:.2f}")
    print(f"   ‚Ä¢ Error: {abs(real_value - predicted_value):.2f}")
    print()

# 14. RESUMEN FINAL
print("\nüìã RESUMEN FINAL:")
print("=" * 20)
print(f"‚úÖ Modelo entrenado exitosamente")
print(f"üìä R¬≤ Score en prueba: {test_r2:.4f}")
print(f"üìâ RMSE en prueba: {test_rmse:.4f}")
print(f"üéØ El modelo explica el {test_r2*100:.1f}% de la varianza en los datos de prueba")

if test_r2 > 0.7:
    print("üéâ ¬°Excelente rendimiento del modelo!")
elif test_r2 > 0.5:
    print("üëç Buen rendimiento del modelo")
elif test_r2 > 0.3:
    print("‚ö†Ô∏è Rendimiento moderado - considera m√°s caracter√≠sticas o diferente modelo")
else:
    print("‚ùå Rendimiento bajo - revisa los datos y considera otros enfoques")

print(f"\nüí° Caracter√≠stica m√°s importante: {feature_importance.iloc[0]['Caracter√≠stica']}")
print(f"üîß Total de caracter√≠sticas usadas: {len(X.columns)}")

print("\nüöÄ ¬°An√°lisis completado!")