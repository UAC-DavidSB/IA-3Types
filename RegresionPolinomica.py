# -*- coding: utf-8 -*-
"""RP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zqc6fQXqhtDox0xOiLB19cqLkeD06kny
"""

# -*- coding: utf-8 -*-
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.impute import SimpleImputer

# =====================================
# 1️⃣ Impresión de Datos
# =====================================
df = pd.read_csv("heart.csv")  # Cambia la ruta según tu archivo

# Limpiar posibles espacios en nombres de columnas
df.columns = df.columns.str.strip()

print("Primeras filas del dataset:")
print(df.head())

print("\nInformación del dataset:")
print(df.info())

print("\nEstadísticas descriptivas:")
print(df.describe())

print("\nValores únicos de las columnas categóricas:")
categorical_features = ["dataset", "sex", "cp", "restecg", "exang", "thal", "fbs"]
for col in categorical_features:
    print(f"{col}: {df[col].unique()}")

# =====================================
# 2️⃣ Preprocesamiento
# =====================================
y = df["num"]
X = df.drop(columns=["id", "num"])

categorical_features = X.select_dtypes(include=['object']).columns.tolist()
numerical_features = [col for col in X.columns if col not in categorical_features]

for col in categorical_features:
    X[col] = X[col].astype(str)

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

poly_regression = Pipeline([
    ('preprocessor', preprocessor),
    ('poly', PolynomialFeatures(degree=2, include_bias=False)),
    ('regressor', LinearRegression())
])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# =====================================
# 3️⃣ Entrenamiento
# =====================================
poly_regression.fit(X_train, y_train)
print("\nModelo entrenado correctamente!")

# =====================================
# 4️⃣ Resultados y ecuación
# =====================================
y_pred = poly_regression.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\nResultados del modelo:")
print(f"Mean Squared Error: {mse:.3f}")
print(f"R^2 Score: {r2:.3f}")

# Obtener nombres de features después de preprocesamiento
preprocessed_features = poly_regression.named_steps['preprocessor'].get_feature_names_out()
poly_features = poly_regression.named_steps['poly'].get_feature_names_out(preprocessed_features)
coefs = poly_regression.named_steps['regressor'].coef_
intercept = poly_regression.named_steps['regressor'].intercept_

print("\nEcuación aproximada del modelo:")
print(f"num = {intercept:.3f}", end='')
for c, f in zip(coefs, poly_features):
    print(f" + ({c:.3f}*{f})", end='')
print()

# =====================================
# 5️⃣ Graficas
# =====================================
plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Valores Reales")
plt.ylabel("Predicciones")
plt.title("Predicciones vs Valores Reales")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.show()

errors = y_test - y_pred
plt.figure(figsize=(8,6))
sns.histplot(errors, kde=True)
plt.xlabel("Error (Real - Predicción)")
plt.title("Distribución de Errores")
plt.show()

# =====================================
# 6️⃣ Ejemplos de predicciones
# =====================================
sample_data = X_test.sample(5, random_state=1)
predictions = poly_regression.predict(sample_data)

print("\nEjemplos de predicciones:")
for i, pred in enumerate(predictions):
    print(f"Paciente {i+1}: Predicción num = {pred:.2f}")

print("\nSe está prediciendo la variable 'num' en base a todas las demás variables del dataset (edad, presión, colesterol, frecuencia cardíaca, y características categóricas como cp, thal, sex, etc.).")