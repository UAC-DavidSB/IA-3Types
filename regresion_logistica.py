# -*- coding: utf-8 -*-
"""Regresion Logistica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ge_Va5m6Us80xZ1QQ85BlCimBOzKu3i0
"""

# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# =====================================
# 1️⃣ Impresión de Datos
# =====================================
df = pd.read_csv("data.csv")  # Cambia según tu ruta
df.columns = df.columns.str.strip()  # limpiar espacios
df = df.drop(columns=['Unnamed: 32'], errors='ignore')  # eliminar columna vacía

print("Primeras filas del dataset:")
print(df.head())

print("\nInformación del dataset:")
print(df.info())

print("\nDistribución de la clase diagnosis:")
print(df['diagnosis'].value_counts())

# =====================================
# 2️⃣ Preprocesamiento
# =====================================
# Convertir la variable target a 0/1
# M = malignant -> 1, B = benign -> 0
le = LabelEncoder()
df['diagnosis'] = le.fit_transform(df['diagnosis'])

# Separar features y target
X = df.drop(columns=['id', 'diagnosis'])
y = df['diagnosis']

# Escalado de features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# División train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# =====================================
# 3️⃣ Entrenamiento
# =====================================
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# =====================================
# 4️⃣ Evaluación del Modelo
# =====================================
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy del modelo: {accuracy:.3f}")

print("\nReporte de clasificación:")
print(classification_report(y_test, y_pred, target_names=['Benigno', 'Maligno']))

# Matriz de confusión
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benigno', 'Maligno'], yticklabels=['Benigno', 'Maligno'])
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.title("Matriz de Confusión")
plt.show()

# =====================================
# 5️⃣ Ecuación del modelo
# =====================================
coefs = model.coef_[0]
intercept = model.intercept_[0]
features = X.columns

print("\nEcuación aproximada del modelo (logit):")
print(f"logit(p) = {intercept:.3f}", end='')
for coef, feat in zip(coefs, features):
    print(f" + ({coef:.3f}*{feat})", end='')
print()
print("\nSe predice 'diagnosis' (1 = Maligno, 0 = Benigno) en base a las 30 features del dataset.")

# =====================================
# 6️⃣ Gráfico de los coeficientes (impacto de cada feature)
# =====================================
coef_df = pd.DataFrame({'Feature': features, 'Coeficiente': coefs})
coef_df = coef_df.sort_values(by='Coeficiente', key=abs, ascending=False)  # ordenar por impacto

plt.figure(figsize=(10,8))
sns.barplot(x='Coeficiente', y='Feature', data=coef_df, color='skyblue')  # <-- usamos color en vez de palette
plt.title("Impacto de cada Feature en la Predicción (coeficientes del modelo)")
plt.xlabel("Coeficiente de regresión logística")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()

# =====================================
# 8️⃣ Gráfico de la ecuación logística con puntos reales
# =====================================
import numpy as np

# Elegimos la feature a visualizar
feature_to_plot = 'radius_mean'
feature_index = list(X.columns).index(feature_to_plot)

# Rango de valores de la feature (escalada)
x_vals = np.linspace(X_scaled[:, feature_index].min(), X_scaled[:, feature_index].max(), 300).reshape(-1,1)

# Dataset temporal para calcular probabilidades
X_temp = np.zeros((x_vals.shape[0], X_scaled.shape[1]))
X_temp[:, feature_index] = x_vals[:,0]
y_probs = model.predict_proba(X_temp)[:,1]

# Gráfico
plt.figure(figsize=(8,6))
plt.plot(x_vals, y_probs, color='red', linewidth=2, label='Curva logística')

# Agregar puntos reales
plt.scatter(X_scaled[:, feature_index], y, alpha=0.5, label='Datos reales')

plt.title(f"Probabilidad de maligno vs {feature_to_plot}")
plt.xlabel(f"{feature_to_plot} (escalada)")
plt.ylabel("Probabilidad de Maligno")
plt.legend()
plt.grid(True)
plt.show()

# =====================================
# 7️⃣ Ejemplos de Predicciones
# =====================================
sample_data = X_test[:5]
sample_pred_prob = model.predict_proba(sample_data)[:,1]
sample_pred_class = model.predict(sample_data)

print("\nEjemplos de predicciones:")
for i in range(len(sample_data)):
    valor_real = y_test.iloc[i]  # valor real de la clase
    prediccion = sample_pred_prob[i]  # probabilidad de maligno
    pred_clase = sample_pred_class[i]
    error = abs(valor_real - prediccion)

    # Formato original
    print(f"Paciente {i+1}: Probabilidad maligno = {prediccion:.2f}, Predicción clase = {'Maligno' if pred_clase==1 else 'Benigno'}")

    # Formato adicional tipo Valor real vs Predicción vs Error
    print(f"   • Valor real: {valor_real:.2f}")
    print(f"   • Predicción: {prediccion:.2f}")
    print(f"   • Error: {error:.2f}\n")

